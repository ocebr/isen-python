include:
  - component: $CI_SERVER_FQDN/components/sast/sast@2.1.0
    inputs:
      excluded_paths: "unit_tests/,integration_tests/"
  - component: $CI_SERVER_FQDN/components/container-scanning/container-scanning@4.2.0
    inputs:
      stage: scan
      cs_image: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA
# The first component will copy the source to the target in Google container registry
  - component: gitlab.com/google-gitlab-components/artifact-registry/upload-artifact-registry@0.1.0
    inputs:
      stage: publish
      source: $IMAGE_SOURCE
      target: $AR_IMAGE:$IMAGE_TAG
    rules:
      - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH || $CI_COMMIT_TAG

# The second component will deploy the image in the Cloud run of the project specified and name ecommerce
  - component: gitlab.com/google-gitlab-components/cloud-run/deploy-cloud-run@0.1.0
    inputs:
      stage: deploy
      image: $AR_IMAGE:$IMAGE_TAG
      project_id: $PROJECT_ID
      region: $LOCATION
      service: $SERVICE



stages:
  - lint
  - test
  - build
  - test-e2e
  - scan
  - publish
  - deploy
  - dast-scan

variables:
  AR_IMAGE: $LOCATION-docker.pkg.dev/$PROJECT_ID/$REPOSITORY/e-commerce
  PROJECT_ID: "apt-quarter-441215-v0"
  LOCATION: "europe-west1"
  REPOSITORY: "isen-app"


pylint:
  stage: lint
  image: python:3.9-slim
  variables:
    # Pylint needs to be configured with django plugins to detect django lint issue
    PYLINT_CONFIG: "--load-plugins=pylint_django  --django-settings-module=Project.settings  --disable=C,R0801"
  before_script:
    - mkdir -p public/badges public/lint
    - echo undefined > public/badges/$CI_JOB_NAME.score
    # Install pylint-gitlab plugin https://pypi.org/project/pylint-gitlab/
    - pip install pylint-gitlab pylint-django
    # Do not forget to install your code dependency otherwise, you will get import errors
    - pip install -r requirements.txt
    - apt update
    - apt install -y bc
  script:
    # execute pylint to have the score
    - pylint --exit-zero $PYLINT_CONFIG  --output-format=text $(find -type f -name "*.py" ! -path "**/.venv/**") | tee /tmp/pylint.txt
    - sed -n 's/^Your code has been rated at \([-0-9.]*\)\/.*/\1/p' /tmp/pylint.txt > public/badges/$CI_JOB_NAME.score
    # Execute pylint to have code quality Gitlab report
    - pylint --exit-zero $PYLINT_CONFIG --output-format=pylint_gitlab.GitlabCodeClimateReporter $(find -type f -name "*.py" ! -path "**/.venv/**") > codeclimate.json
    # execute pylint to have a html report
    - pylint --exit-zero $PYLINT_CONFIG --output-format=pylint_gitlab.GitlabPagesHtmlReporter $(find -type f -name "*.py" ! -path "**/.venv/**") > public/lint/index.html
    - |
      echo "Your score is: $(cat public/badges/$CI_JOB_NAME.score)"
      if [ "$(echo "$(cat public/badges/pylint.score) < 8"| bc)" -eq 1 ]; then
          echo "Pylint score is less than 8, failing the job.";
          exit 1;
      fi
  after_script:
    - anybadge --overwrite --label $CI_JOB_NAME --value=$(cat public/badges/$CI_JOB_NAME.score) --file=public/badges/$CI_JOB_NAME.svg 4=red 6=orange 8=yellow 10=green
  artifacts:
    paths:
      # Put in artifact the html report and the badge
      - public
    reports:
      # Give Gitlab the code quality report to be displayed in merge request
      codequality: codeclimate.json
  rules:
    - when: always

docker-hadolint:
  stage: lint
  image: hadolint/hadolint:v2.12.0-alpine
  script:
    - mkdir -p reports
    - hadolint -f gitlab_codeclimate Dockerfile > reports/hadolint-$(md5sum Dockerfile | cut -d" " -f1).json
  artifacts:
    name: "$CI_JOB_NAME artifacts from $CI_PROJECT_NAME on $CI_COMMIT_REF_SLUG"
    expire_in: 1 day
    when: always
    reports:
      codequality:
        - "reports/*"
    paths:
      - "reports/*"
  rules:
    - when: always

pytest_unit:
  stage: test
  image: python:3.9-slim
  before_script:
    - pip install -r requirements.txt
    - pip install pytest-gitlab-code-quality
  script:
    - python -m pytest unit_tests/ --gitlab-code-quality-report=pytest-warnings-unit.json
  artifacts:
    reports:
      codequality: pytest-warnings-unit.json
  rules:
    - when: always

pytest_integration:
  stage: test
  image: python:3.9-slim
  before_script:
    - pip install -r requirements.txt
    - pip install pytest-gitlab-code-quality
  script:
    - python -m pytest integration_tests/ --gitlab-code-quality-report=pytest-warnings-integration.json
  artifacts:
    reports:
      codequality: pytest-warnings-integration.json
  rules:
    - when: always

semgrep-sast:
  rules:
    - when: always

build:
  image: docker:20.10.16
  stage: build
  services:
    - name: docker:20.10.16-dind
      alias: docker
  variables:
    DOCKER_HOST: tcp://docker:2375
    DOCKER_TLS_CERTDIR: ""

  script:
    - echo "$CI_REGISTRY_PASSWORD" | docker login $CI_REGISTRY -u $CI_REGISTRY_USER --password-stdin
    - docker build -t $IMAGE_SOURCE -f Dockerfile .
    - docker push $IMAGE_SOURCE
    - echo "IMAGE_SOURCE=$IMAGE_SOURCE" >> docker.env
    - echo "IMAGE_TAG=$IMAGE_TAG" >> docker.env
  rules:
    - if: $CI_COMMIT_TAG
      variables:
        IMAGE_TAG: $CI_COMMIT_TAG
        IMAGE_SOURCE: $CI_REGISTRY_IMAGE:$IMAGE_TAG
    - when: always
      variables:
        IMAGE_TAG: $CI_COMMIT_SHORT_SHA
        IMAGE_SOURCE: $CI_REGISTRY_IMAGE:$IMAGE_TAG
  artifacts:
    reports:
      dotenv: docker.env


generating_sbom:
  stage: build
  image: debian:stable-slim
  before_script:
    - apt-get update && apt-get install -y curl
    - curl -sSfL https://raw.githubusercontent.com/anchore/syft/main/install.sh | sh -s -- -b /usr/local/bin
  script:
    - syft dir:$CI_PROJECT_DIR -o syft-json=syft-sbom.json
  artifacts:
    paths:
      - syft-sbom.json
  rules:
    - when: always

grype:
  image: debian:stable-slim
  stage: scan
  before_script:
    - apt-get update && apt-get install -y curl
    - curl -sSfL https://raw.githubusercontent.com/anchore/grype/main/install.sh | sh -s -- -b /usr/local/bin
  script:
    - grype sbom:syft-sbom.json 
  rules:
    - when: always


cypress tests:
  image: cypress/browsers:node-22.11.0-chrome-130.0.6723.69-1-ff-132.0-edge-130.0.2849.56-1
  stage: test-e2e
  services:
    - name: $IMAGE_SOURCE
      alias: oc-commerce
  script:
    # run Cypress tests
    - npm install cypress --save-dev
    - npx cypress run --browser firefox --config baseUrl=http://oc-commerce:8080
  rules:  
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH

deploy-cloud-run:
  rules:
    - if: $CI_COMMIT_TAG
      variables:
        SERVICE: e-commerce
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
      variables:
        SERVICE: staging-e-commerce
    - when: never
  after_script:
    - echo "SERVICE=$SERVICE" >> service.env
  artifacts:
    reports:
      dotenv: service.env


# This job will create Gitlab Environment related to main branch which is our  environment
environment:
  image: gcr.io/google.com/cloudsdktool/google-cloud-cli:489.0.0-stable
  stage: deploy
  # We reference the Google identity configured in Gitlab, so any gcloud command is able to authenticate to Google
  identity: google_cloud
  # We need deploy-clour-run job to run before this one
  needs: 
    - deploy-cloud-run
  script:
  # We are retrieving our service url since it's kinda of random, we need it expose the environment
    - SERVICE_URL=$(gcloud run services describe $SERVICE --project $PROJECT_ID  --region $LOCATION --format 'value(status.url)')
    - echo "Environment is deployed at $SERVICE_URL"
    - echo "SERVICE_URL=$SERVICE_URL" >> deploy.env
  artifacts:
    reports:
    # Putting SERVICE_URL in dotenv to access the variable in environement section
      dotenv: deploy.env
    # Configuring a Gitlab environment
  environment: 
    name: $ENVIRONMENT
    url: $SERVICE_URL
    # Only deploying to production when running on default branch which is main
  rules:  
    - if: $CI_COMMIT_TAG
      variables:
        ENVIRONMENT: production
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH
      variables:
        ENVIRONMENT: staging
    - when: never

owasp zap full scan:
  stage: dast-scan
  image: docker:20.10.16
  services: 
    - name: docker:20.10.16-dind
      command: ["--tls=false", "--host=tcp://0.0.0.0:2375"]
  variables:  
    ZAP_REPORTS_DIR: $CI_PROJECT_DIR/zap/wrk/reports
    ZAP_WORKING_DIR: $CI_PROJECT_DIR/zap/wrk
    ZAP_JSON_REPORT_NAME: "zap_fullscan_report.json"
    ZAP_API_IMAGE: zaproxy/zap-stable
  script:
    - export ZAP_TARGET=$SERVICE_URL 
    - mkdir -p $ZAP_REPORTS_DIR $ZAP_WORKING_DIR
    - echo report file "$ZAP_REPORTS_DIR/$ZAP_JSON_REPORT_NAME"
    - touch "$ZAP_REPORTS_DIR/$ZAP_JSON_REPORT_NAME"
    - chmod a+w "$ZAP_REPORTS_DIR/$ZAP_JSON_REPORT_NAME"
    - docker pull --quiet $ZAP_API_IMAGE
    - docker run --network="host" --volume $ZAP_REPORTS_DIR:/zap/wrk/reports/:rw  --volume $ZAP_WORKING_DIR:/zap/wrk/:rw --volume /var/run/docker.sock:/var/run/docker.sock $ZAP_API_IMAGE  zap-baseline.py -t ${ZAP_TARGET}  -J "/zap/wrk/reports/$ZAP_JSON_REPORT_NAME" -l PASS
  artifacts:
    reports:
      dast: "$ZAP_REPORTS_DIR/$ZAP_JSON_REPORT_NAME"
    paths: 
      - $ZAP_REPORTS_DIR/
    when: always
  allow_failure: true
  rules:  
    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH

